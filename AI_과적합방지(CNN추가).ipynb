{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_과적합방지(CNN추가).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "MhoQ0WE77laV"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmongsil1105/colab_ipynb/blob/main/AI_%EA%B3%BC%EC%A0%81%ED%95%A9%EB%B0%A9%EC%A7%80(CNN%EC%B6%94%EA%B0%80).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhoQ0WE77laV"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "_ckMIh7O7s6D"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "vasWnqRgy1H4"
      },
      "source": [
        "#@title MIT License\n",
        "#\n",
        "# Copyright (c) 2017 François Chollet\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYysdyb-CaWM"
      },
      "source": [
        "# 첫 번째 신경망 훈련하기: 기초적인 분류 문제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Uhzt6vVIB2"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />TensorFlow.org에서 보기</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/tutorials/keras/classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩(Colab)에서 실행하기</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ko/tutorials/keras/classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />깃허브(GitHub) 소스 보기</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ko/tutorials/keras/classification.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJjNjjy3Zbz0"
      },
      "source": [
        "Note: 이 문서는 텐서플로 커뮤니티에서 번역했습니다. 커뮤니티 번역 활동의 특성상 정확한 번역과 최신 내용을 반영하기 위해 노력함에도\n",
        "불구하고 [공식 영문 문서](https://www.tensorflow.org/?hl=en)의 내용과 일치하지 않을 수 있습니다.\n",
        "이 번역에 개선할 부분이 있다면\n",
        "[tensorflow/docs-l10n](https://github.com/tensorflow/docs-l10n/) 깃헙 저장소로 풀 리퀘스트를 보내주시기 바랍니다.\n",
        "문서 번역이나 리뷰에 참여하려면\n",
        "[docs-ko@tensorflow.org](https://groups.google.com/a/tensorflow.org/forum/#!forum/docs-ko)로\n",
        "메일을 보내주시기 바랍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbVhjPpzn6BM"
      },
      "source": [
        "이 튜토리얼에서는 운동화나 셔츠 같은 옷 이미지를 분류하는 신경망 모델을 훈련합니다. 상세 내용을 모두 이해하지 못해도 괜찮습니다. 여기서는 완전한 텐서플로(TensorFlow) 프로그램을 빠르게 살펴 보겠습니다. 자세한 내용은 앞으로 배우면서 더 설명합니다.\n",
        "\n",
        "여기에서는 텐서플로 모델을 만들고 훈련할 수 있는 고수준 API인 [tf.keras](https://www.tensorflow.org/guide/keras)를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzLKpmZICaWN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87c7932d-c5c1-4a07-f8bc-be8f05f755e3"
      },
      "source": [
        "# tensorflow와 tf.keras를 임포트합니다\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# 헬퍼(helper) 라이브러리를 임포트합니다\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR0EdgrLCaWR"
      },
      "source": [
        "## 패션 MNIST 데이터셋 임포트하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLdCchMdCaWQ"
      },
      "source": [
        "10개의 범주(category)와 70,000개의 흑백 이미지로 구성된 [패션 MNIST](https://github.com/zalandoresearch/fashion-mnist) 데이터셋을 사용하겠습니다. 이미지는 해상도(28x28 픽셀)가 낮고 다음처럼 개별 옷 품목을 나타냅니다:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
        "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>그림 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">패션-MNIST 샘플</a> (Zalando, MIT License).<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "패션 MNIST는 컴퓨터 비전 분야의 \"Hello, World\" 프로그램격인 고전 [MNIST](http://yann.lecun.com/exdb/mnist/) 데이터셋을 대신해서 자주 사용됩니다. MNIST 데이터셋은 손글씨 숫자(0, 1, 2 등)의 이미지로 이루어져 있습니다. 여기서 사용하려는 옷 이미지와 동일한 포맷입니다.\n",
        "\n",
        "패션 MNIST는 일반적인 MNIST 보다 조금 더 어려운 문제이고 다양한 예제를 만들기 위해 선택했습니다. 두 데이터셋은 비교적 작기 때문에 알고리즘의 작동 여부를 확인하기 위해 사용되곤 합니다. 코드를 테스트하고 디버깅하는 용도로 좋습니다.\n",
        "\n",
        "네트워크를 훈련하는데 60,000개의 이미지를 사용합니다. 그다음 네트워크가 얼마나 정확하게 이미지를 분류하는지 10,000개의 이미지로 평가하겠습니다. 패션 MNIST 데이터셋은 텐서플로에서 바로 임포트하여 적재할 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MqDQO0KCaWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8de1a0be-fd5c-4f93-c51a-0b7937286546"
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9FDsUlxCaWW"
      },
      "source": [
        "load_data() 함수를 호출하면 네 개의 넘파이(NumPy) 배열이 반환됩니다:\n",
        "\n",
        "* `train_images`와 `train_labels` 배열은 모델 학습에 사용되는 *훈련 세트*입니다.\n",
        "* `test_images`와 `test_labels` 배열은 모델 테스트에 사용되는 *테스트 세트*입니다.\n",
        "\n",
        "이미지는 28x28 크기의 넘파이 배열이고 픽셀 값은 0과 255 사이입니다. *레이블*(label)은 0에서 9까지의 정수 배열입니다. 이 값은 이미지에 있는 옷의 *클래스*(class)를 나타냅니다:\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>레이블</th>\n",
        "    <th>클래스</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>T-shirt/top</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Trouser</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>2</td>\n",
        "    <td>Pullover</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>3</td>\n",
        "    <td>Dress</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>4</td>\n",
        "    <td>Coat</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>5</td>\n",
        "    <td>Sandal</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>6</td>\n",
        "    <td>Shirt</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>7</td>\n",
        "    <td>Sneaker</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>8</td>\n",
        "    <td>Bag</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>9</td>\n",
        "    <td>Ankle boot</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "각 이미지는 하나의 레이블에 매핑되어 있습니다. 데이터셋에 *클래스 이름*이 들어있지 않기 때문에 나중에 이미지를 출력할 때 사용하기 위해 별도의 변수를 만들어 저장합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjnLH5S2CaWx"
      },
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brm0b_KACaWX"
      },
      "source": [
        "## 데이터 탐색\n",
        "\n",
        "모델을 훈련하기 전에 데이터셋 구조를 살펴보죠. 다음 코드는 훈련 세트에 60,000개의 이미지가 있다는 것을 보여줍니다. 각 이미지는 28x28 픽셀로 표현됩니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW5k_xz1CaWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcfd6a64-85ba-43da-c8a8-8e656912dec0"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIAcvQqMCaWf"
      },
      "source": [
        "비슷하게 훈련 세트에는 60,000개의 레이블이 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRFYHB2mCaWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87978fae-975e-4c41-eb1c-546eeb107c49"
      },
      "source": [
        "len(train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSlYxFuRCaWk"
      },
      "source": [
        "각 레이블은 0과 9사이의 정수입니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKnCTHz4CaWg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66355d84-0521-4ea2-cf23-1205355e20db"
      },
      "source": [
        "train_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMPI88iZpO2T"
      },
      "source": [
        "테스트 세트에는 10,000개의 이미지가 있습니다. 이 이미지도 28x28 픽셀로 표현됩니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KFnYlcwCaWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b990865e-4f8b-428a-c3a2-4f6785e86748"
      },
      "source": [
        "test_images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd0A0Iu0CaWq"
      },
      "source": [
        "테스트 세트는 10,000개의 이미지에 대한 레이블을 가지고 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJmPr5-ACaWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89692dc2-1039-48ad-a537-82bcc8e15e7a"
      },
      "source": [
        "len(test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES6uQoLKCaWr"
      },
      "source": [
        "## 데이터 전처리\n",
        "\n",
        "네트워크를 훈련하기 전에 데이터를 전처리해야 합니다. 훈련 세트에 있는 첫 번째 이미지를 보면 픽셀 값의 범위가 0~255 사이라는 것을 알 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4VEw8Ud9Quh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "188634fa-fdcc-4b19-d8a8-c56289ad9d81"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images[0])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz7l27Lz9S1P"
      },
      "source": [
        "신경망 모델에 주입하기 전에 이 값의 범위를 0~1 사이로 조정하겠습니다. 이렇게 하려면 255로 나누어야 합니다. *훈련 세트*와 *테스트 세트*를 동일한 방식으로 전처리하는 것이 중요합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW5WzIPlCaWv"
      },
      "source": [
        "train_images = train_images.reshape((60000, 28, 28 ,1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee638AlnCaWz"
      },
      "source": [
        "*훈련 세트*에서 처음 25개 이미지와 그 아래 클래스 이름을 출력해 보죠. 데이터 포맷이 올바른지 확인하고 네트워크 구성과 훈련할 준비를 마칩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZTImqg_CaW1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "008d0045-23d7-4d69-b52a-05f7b5b0712b"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-54389fd111e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2651\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2652\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5626\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    698\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 699\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (28, 28, 1) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAG8AAABvCAYAAADixZ5gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAABX0lEQVR4nO3UwWkDUQxAwf0hJdjnbP+12EX4nPSgNLAGO8QkD2au0kHwQGtmNpre/voAfk68MPHCxAsTL0y8sPdnlk+n0+z7/qJTOHK9Xr9m5nw0eyrevu/b5XL5nat4yFrrdm/mbYaJFyZemHhh4oWJFyZemHhh4oWJFyZemHhh4oWJFyZemHhh4oWJFyZemHhh4oWJFyZemHhh4oWJFyZemHhh4oWJFyZemHhh4oWJFyZemHhh4oWJFyZemHhh4oWJFyZemHhh4oWJFyZemHhh4oWJFyZemHhh4oWJFyZemHhh4oWJFyZemHhh4oWJFyZemHhh4oWJFyZemHhh4oWJFyZemHhh4oWJFyZemHhh4oWJFyZemHhh4oWJFyZemHhh4oWJFyZemHhh4oWJFyZe2JqZx5fX+ty27fa6czjwMTPno8FT8fhfvM0w8cLECxMvTLww8cLECxMvTLywb27uGn/O1w/YAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59veuiEZCaW4"
      },
      "source": [
        "## 모델 구성\n",
        "\n",
        "신경망 모델을 만들려면 모델의 층을 구성한 다음 모델을 컴파일합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxg1XGm0eOBy"
      },
      "source": [
        "### 층 설정\n",
        "\n",
        "신경망의 기본 구성 요소는 *층*(layer)입니다. 층은 주입된 데이터에서 표현을 추출합니다. 아마도 문제를 해결하는데 더 의미있는 표현이 추출될 것입니다.\n",
        "\n",
        "대부분 딥러닝은 간단한 층을 연결하여 구성됩니다. `tf.keras.layers.Dense`와 같은 층들의 가중치(parameter)는 훈련하는 동안 학습됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ODch-OFCaW4"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(64, activity_regularizer=tf.keras.regularizers.l1(0.01), kernel_initializer='he_normal',\n",
        "                       kernel_regularizer=tf.keras.regularizers.l2(0.01), activation='relu'),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(10, activity_regularizer=tf.keras.regularizers.l1(0.01), kernel_initializer='he_normal', \n",
        "                       kernel_regularizer=tf.keras.regularizers.l2(0.01), activation='softmax'),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gut8A_7rCaW6"
      },
      "source": [
        "이 네트워크의 첫 번째 층인 `tf.keras.layers.Flatten`은 2차원 배열(28 x 28 픽셀)의 이미지 포맷을 28 * 28 = 784 픽셀의 1차원 배열로 변환합니다. 이 층은 이미지에 있는 픽셀의 행을 펼쳐서 일렬로 늘립니다. 이 층에는 학습되는 가중치가 없고 데이터를 변환하기만 합니다.\n",
        "\n",
        "픽셀을 펼친 후에는 두 개의 `tf.keras.layers.Dense` 층이 연속되어 연결됩니다. 이 층을 밀집 연결(densely-connected) 또는 완전 연결(fully-connected) 층이라고 부릅니다. 첫 번째 `Dense` 층은 128개의 노드(또는 뉴런)를 가집니다. 두 번째 (마지막) 층은 10개의 노드의 *소프트맥스*(softmax) 층입니다. 이 층은 10개의 확률을 반환하고 반환된 값의 전체 합은 1입니다. 각 노드는 현재 이미지가 10개 클래스 중 하나에 속할 확률을 출력합니다.\n",
        "\n",
        "### 모델 컴파일\n",
        "\n",
        "모델을 훈련하기 전에 필요한 몇 가지 설정이 모델 *컴파일* 단계에서 추가됩니다:\n",
        "\n",
        "* *손실 함수*(Loss function)-훈련 하는 동안 모델의 오차를 측정합니다. 모델의 학습이 올바른 방향으로 향하도록 이 함수를 최소화해야 합니다.\n",
        "* *옵티마이저*(Optimizer)-데이터와 손실 함수를 바탕으로 모델의 업데이트 방법을 결정합니다.\n",
        "* *지표*(Metrics)-훈련 단계와 테스트 단계를 모니터링하기 위해 사용합니다. 다음 예에서는 올바르게 분류된 이미지의 비율인 *정확도*를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lhan11blCaW7"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#sgd = keras.optimizers.SGD(learning_rate=0.001)\n",
        "#model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy',\n",
        "#              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKF6uW-BCaW-"
      },
      "source": [
        "## 모델 훈련\n",
        "\n",
        "신경망 모델을 훈련하는 단계는 다음과 같습니다:\n",
        "\n",
        "1. 훈련 데이터를 모델에 주입합니다-이 예에서는 `train_images`와 `train_labels` 배열입니다.\n",
        "2. 모델이 이미지와 레이블을 매핑하는 방법을 배웁니다.\n",
        "3. 테스트 세트에 대한 모델의 예측을 만듭니다-이 예에서는 `test_images` 배열입니다. 이 예측이 `test_labels` 배열의 레이블과 맞는지 확인합니다.\n",
        "\n",
        "훈련을 시작하기 위해 `model.fit` 메서드를 호출하면 모델이 훈련 데이터를 학습합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvwvpA64CaW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f908bfb-73e2-4d8e-bf0c-5f180db49131"
      },
      "source": [
        "model.fit(train_images, train_labels, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 41s 6ms/step - loss: 0.9523 - accuracy: 0.8475\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.6676 - accuracy: 0.8877\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.6266 - accuracy: 0.9006\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.6012 - accuracy: 0.9087\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.5807 - accuracy: 0.9151\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.5667 - accuracy: 0.9206\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.5545 - accuracy: 0.9246\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.5461 - accuracy: 0.9280\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.5339 - accuracy: 0.9330\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.5233 - accuracy: 0.9358\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4490137750>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3ZVOhugCaXA"
      },
      "source": [
        "모델이 훈련되면서 손실과 정확도 지표가 출력됩니다. 이 모델은 훈련 세트에서 약 0.88(88%) 정도의 정확도를 달성합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEw4bZgGCaXB"
      },
      "source": [
        "## 정확도 평가\n",
        "\n",
        "그다음 테스트 세트에서 모델의 성능을 비교합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VflXLEeECaXC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0725b7df-df48-4d48-c0fe-a0f1a44264dc"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "\n",
        "print('\\n테스트 정확도:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 0.5806 - accuracy: 0.9024\n",
            "\n",
            "테스트 정확도: 0.902400016784668\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWfgsmVXCaXG"
      },
      "source": [
        "테스트 세트의 정확도가 훈련 세트의 정확도보다 조금 낮습니다. 훈련 세트의 정확도와 테스트 세트의 정확도 사이의 차이는 *과대적합*(overfitting) 때문입니다. 과대적합은 머신러닝 모델이 훈련 데이터보다 새로운 데이터에서 성능이 낮아지는 현상을 말합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsoS7CPDCaXH"
      },
      "source": [
        "## 예측 만들기\n",
        "\n",
        "훈련된 모델을 사용하여 이미지에 대한 예측을 만들 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl91RPhdCaXI"
      },
      "source": [
        "predictions = model.predict(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9Kk1voUCaXJ"
      },
      "source": [
        "여기서는 테스트 세트에 있는 각 이미지의 레이블을 예측했습니다. 첫 번째 예측을 확인해 보죠:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DmJEUinCaXK"
      },
      "source": [
        "predictions[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hw1hgeSCaXN"
      },
      "source": [
        "이 예측은 10개의 숫자 배열로 나타납니다. 이 값은 10개의 옷 품목에 상응하는 모델의 신뢰도(confidence)를 나타냅니다. 가장 높은 신뢰도를 가진 레이블을 찾아보죠:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsqenuPnCaXO"
      },
      "source": [
        "np.argmax(predictions[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E51yS7iCCaXO"
      },
      "source": [
        "모델은 이 이미지가 앵클 부츠(`class_name[9]`)라고 가장 확신하고 있습니다. 이 값이 맞는지 테스트 레이블을 확인해 보죠:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd7Pgsu6CaXP"
      },
      "source": [
        "test_labels[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygh2yYC972ne"
      },
      "source": [
        "10개 클래스에 대한 예측을 모두 그래프로 표현해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvYmmrpIy6Y1"
      },
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array[i], true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Ov9OFDMmOD"
      },
      "source": [
        "0번째 원소의 이미지, 예측, 신뢰도 점수 배열을 확인해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV5jw-5HwSmO"
      },
      "source": [
        "i = 0\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions, test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions,  test_labels)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko-uzOufSCSe"
      },
      "source": [
        "i = 12\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions, test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions,  test_labels)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgdvGD52CaXR"
      },
      "source": [
        "몇 개의 이미지의 예측을 출력해 보죠. 올바르게 예측된 레이블은 파란색이고 잘못 예측된 레이블은 빨강색입니다. 숫자는 예측 레이블의 신뢰도 퍼센트(100점 만점)입니다. 신뢰도 점수가 높을 때도 잘못 예측할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQlnbqaw2Qu_"
      },
      "source": [
        "# 처음 X 개의 테스트 이미지와 예측 레이블, 진짜 레이블을 출력합니다\n",
        "# 올바른 예측은 파랑색으로 잘못된 예측은 빨강색으로 나타냅니다\n",
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions, test_labels, test_images)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_value_array(i, predictions, test_labels)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R32zteKHCaXT"
      },
      "source": [
        "마지막으로 훈련된 모델을 사용하여 한 이미지에 대한 예측을 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRJ7JU7JCaXT"
      },
      "source": [
        "# 테스트 세트에서 이미지 하나를 선택합니다\n",
        "img = test_images[0]\n",
        "\n",
        "print(img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz3bVp21CaXV"
      },
      "source": [
        "`tf.keras` 모델은 한 번에 샘플의 묶음 또는 *배치*(batch)로 예측을 만드는데 최적화되어 있습니다. 하나의 이미지를 사용할 때에도 2차원 배열로 만들어야 합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDFh5yF_CaXW"
      },
      "source": [
        "# 이미지 하나만 사용할 때도 배치에 추가합니다\n",
        "img = (np.expand_dims(img,0))\n",
        "\n",
        "print(img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ5wLTkcCaXY"
      },
      "source": [
        "이제 이 이미지의 예측을 만듭니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_rzNSdrCaXY"
      },
      "source": [
        "predictions_single = model.predict(img)\n",
        "\n",
        "print(predictions_single)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ai-cpLjO-3A"
      },
      "source": [
        "plot_value_array(0, predictions_single, test_labels)\n",
        "_ = plt.xticks(range(10), class_names, rotation=45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU1Y2OAMCaXb"
      },
      "source": [
        "`model.predict`는 2차원 넘파이 배열을 반환하므로 첫 번째 이미지의 예측을 선택합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tRmdq_8CaXb"
      },
      "source": [
        "np.argmax(predictions_single[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFc2HbEVCaXd"
      },
      "source": [
        "이전과 마찬가지로 모델의 예측은 레이블 9입니다."
      ]
    }
  ]
}