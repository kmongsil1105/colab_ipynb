{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AI_PyTorch(DataLoader를 이용한 선형회귀모델).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMP4eDXJhG1gFnqlOq4+RG6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmongsil1105/colab_ipynb/blob/main/AI_PyTorch(DataLoader%EB%A5%BC_%EC%9D%B4%EC%9A%A9%ED%95%9C_%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80%EB%AA%A8%EB%8D%B8).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8i6S7zhmUdVD"
      },
      "source": [
        "파이토치에서는 데이터를 좀 더 쉽게 다룰 수 있도록 유용한 도구로서 데이터셋(Dataset)과 데이터로더(DataLoader)를 제공"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKAgPNZdUfX_"
      },
      "source": [
        "텐서를 입력받아 Dataset의 형태로 변환해주는 TensorDataset을 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghn2GlVbURrm"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JesmDc5mUqeo"
      },
      "source": [
        "TensorDataset과 DataLoader를 임포트합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wODF4-DKUniv"
      },
      "source": [
        "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
        "from torch.utils.data import DataLoader # 데이터로더"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTyymNOlUuk-"
      },
      "source": [
        "TensorDataset은 기본적으로 텐서를 입력으로 받습니다. 텐서 형태로 데이터를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs-mCnrbUy_r"
      },
      "source": [
        "x_train  =  torch.FloatTensor([[73,  80,  75],   # x_train ==> 입력값\n",
        "                               [93,  88,  93], \n",
        "                               [89,  91,  90], \n",
        "                               [96,  98,  100],   \n",
        "                               [73,  66,  70]])  \n",
        "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])  # y_train ==> 학습시킬 정답!!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5ImAgLHU1op"
      },
      "source": [
        "이제 이를 TensorDataset의 입력으로 사용하고 dataset으로 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhiWjDTFU4vB"
      },
      "source": [
        "dataset = TensorDataset(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoJNlB8QVAm3"
      },
      "source": [
        "파이토치의 데이터셋을 만들었다면 데이터로더를 사용 가능합니다. 데이터로더는 기본적으로 2개의 인자를 입력받는다. \n",
        "\n",
        "하나는 데이터셋, 미니 배치의 크기입니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8p8lMX-lVBep"
      },
      "source": [
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True) # batch_size=2 :: 입력값 텐서에서 한번에 2개씩 읽어라!!!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObxLchS2VJUf"
      },
      "source": [
        "이제 모델과 옵티마이저를 설계합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFzV1-WfxL0C"
      },
      "source": [
        " model = nn.Linear(3,1) \n",
        " \n",
        " ==> nn.Module안에 정의되어 있는 nn.Linear()함수 대신에 \n",
        "     Class를 이용해서 정의한 모델을 사용하는 code는 \n",
        "\n",
        "\n",
        " class LinearRegressionModel(nn.Module): \n",
        "   \n",
        "    def __init__(self):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.linear = nn.Linear(3, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        return self.linear(x)\n",
        "\n",
        "model = LinearRegressionModel()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeyoPOaXVKZe"
      },
      "source": [
        "# 모델을 선언 및 초기화. 단순 선형 회귀이므로 input_dim=1, output_dim=1.\n",
        "# model = nn.Linear(1,1)  ==> nn.Module 클래스\n",
        "\n",
        "# model = nn.Linear(3,1) ==> nn.Module안에 정의되어 있는 nn.Linear()함수 대신에 \n",
        "#                            Class를 이용해서 정의한 모델을 사용하는 code는 아래쪽에!!! \n",
        "###########################################  \"model = nn.Linear(3,1)\" 와 같은 역할을 한다!!!\n",
        "class LinearRegressionModel(nn.Module): \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(3, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "model = LinearRegressionModel()\n",
        "##########################################\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzBK4FuhVNAl"
      },
      "source": [
        "이제 훈련을 진행합니다. \n",
        "\n",
        "아래 코드에서는 batch_idx와 samples를 주석 처리했는데 어떤 식으로 훈련되고 있는지 궁금하다면 \n",
        "\n",
        "주석 처리를 해제하고 훈련시켜보시기 바랍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47lbXMqPVVCW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "538babab-b077-4b29-fd56-f15649b8c02c"
      },
      "source": [
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    #print(batch_idx)\n",
        "    #print(samples)\n",
        "    print(\"--- \" + str(batch_idx) + \" + \" + str(samples) + \" ---\")\n",
        "    x_train, y_train = samples\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "    # cost로 H(x) 계산\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(   # batch_size=2 :: 입력값 텐서에서 한번에 2개씩 읽어라!!!\n",
        "        epoch, nb_epochs, batch_idx+1, len(dataloader),       # 5개의 텐서 입력값이므로 2개씩 읽어서 작업하고 마지막에는 남은 1개를 읽어서 작업\n",
        "        cost.item()                                           # 그래서 \"총 3번씩\" 처리!!!\n",
        "        ))                                                    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 0 + [tensor([[73., 80., 75.],\n",
            "        [89., 91., 90.]]), tensor([[152.],\n",
            "        [180.]])] ---\n",
            "Epoch    0/20 Batch 1/3 Cost: 2.428375\n",
            "--- 1 + [tensor([[ 96.,  98., 100.],\n",
            "        [ 93.,  88.,  93.]]), tensor([[196.],\n",
            "        [185.]])] ---\n",
            "Epoch    0/20 Batch 2/3 Cost: 5.782719\n",
            "--- 2 + [tensor([[73., 66., 70.]]), tensor([[142.]])] ---\n",
            "Epoch    0/20 Batch 3/3 Cost: 7.325375\n",
            "--- 0 + [tensor([[89., 91., 90.],\n",
            "        [93., 88., 93.]]), tensor([[180.],\n",
            "        [185.]])] ---\n",
            "Epoch    1/20 Batch 1/3 Cost: 3.779926\n",
            "--- 1 + [tensor([[ 73.,  80.,  75.],\n",
            "        [ 96.,  98., 100.]]), tensor([[152.],\n",
            "        [196.]])] ---\n",
            "Epoch    1/20 Batch 2/3 Cost: 5.100436\n",
            "--- 2 + [tensor([[73., 66., 70.]]), tensor([[142.]])] ---\n",
            "Epoch    1/20 Batch 3/3 Cost: 8.117056\n",
            "--- 0 + [tensor([[93., 88., 93.],\n",
            "        [73., 80., 75.]]), tensor([[185.],\n",
            "        [152.]])] ---\n",
            "Epoch    2/20 Batch 1/3 Cost: 5.381450\n",
            "--- 1 + [tensor([[89., 91., 90.],\n",
            "        [73., 66., 70.]]), tensor([[180.],\n",
            "        [142.]])] ---\n",
            "Epoch    2/20 Batch 2/3 Cost: 4.418544\n",
            "--- 2 + [tensor([[ 96.,  98., 100.]]), tensor([[196.]])] ---\n",
            "Epoch    2/20 Batch 3/3 Cost: 1.634493\n",
            "--- 0 + [tensor([[73., 80., 75.],\n",
            "        [73., 66., 70.]]), tensor([[152.],\n",
            "        [142.]])] ---\n",
            "Epoch    3/20 Batch 1/3 Cost: 5.992731\n",
            "--- 1 + [tensor([[ 93.,  88.,  93.],\n",
            "        [ 96.,  98., 100.]]), tensor([[185.],\n",
            "        [196.]])] ---\n",
            "Epoch    3/20 Batch 2/3 Cost: 3.137472\n",
            "--- 2 + [tensor([[89., 91., 90.]]), tensor([[180.]])] ---\n",
            "Epoch    3/20 Batch 3/3 Cost: 3.169537\n",
            "--- 0 + [tensor([[89., 91., 90.],\n",
            "        [73., 66., 70.]]), tensor([[180.],\n",
            "        [142.]])] ---\n",
            "Epoch    4/20 Batch 1/3 Cost: 5.020202\n",
            "--- 1 + [tensor([[ 93.,  88.,  93.],\n",
            "        [ 96.,  98., 100.]]), tensor([[185.],\n",
            "        [196.]])] ---\n",
            "Epoch    4/20 Batch 2/3 Cost: 3.302127\n",
            "--- 2 + [tensor([[73., 80., 75.]]), tensor([[152.]])] ---\n",
            "Epoch    4/20 Batch 3/3 Cost: 6.145612\n",
            "--- 0 + [tensor([[73., 80., 75.],\n",
            "        [93., 88., 93.]]), tensor([[152.],\n",
            "        [185.]])] ---\n",
            "Epoch    5/20 Batch 1/3 Cost: 5.992876\n",
            "--- 1 + [tensor([[ 96.,  98., 100.],\n",
            "        [ 73.,  66.,  70.]]), tensor([[196.],\n",
            "        [142.]])] ---\n",
            "Epoch    5/20 Batch 2/3 Cost: 4.156686\n",
            "--- 2 + [tensor([[89., 91., 90.]]), tensor([[180.]])] ---\n",
            "Epoch    5/20 Batch 3/3 Cost: 2.462672\n",
            "--- 0 + [tensor([[ 93.,  88.,  93.],\n",
            "        [ 96.,  98., 100.]]), tensor([[185.],\n",
            "        [196.]])] ---\n",
            "Epoch    6/20 Batch 1/3 Cost: 4.413684\n",
            "--- 1 + [tensor([[73., 80., 75.],\n",
            "        [89., 91., 90.]]), tensor([[152.],\n",
            "        [180.]])] ---\n",
            "Epoch    6/20 Batch 2/3 Cost: 3.802869\n",
            "--- 2 + [tensor([[73., 66., 70.]]), tensor([[142.]])] ---\n",
            "Epoch    6/20 Batch 3/3 Cost: 10.277514\n",
            "--- 0 + [tensor([[ 89.,  91.,  90.],\n",
            "        [ 96.,  98., 100.]]), tensor([[180.],\n",
            "        [196.]])] ---\n",
            "Epoch    7/20 Batch 1/3 Cost: 2.538888\n",
            "--- 1 + [tensor([[93., 88., 93.],\n",
            "        [73., 66., 70.]]), tensor([[185.],\n",
            "        [142.]])] ---\n",
            "Epoch    7/20 Batch 2/3 Cost: 7.689456\n",
            "--- 2 + [tensor([[73., 80., 75.]]), tensor([[152.]])] ---\n",
            "Epoch    7/20 Batch 3/3 Cost: 8.705273\n",
            "--- 0 + [tensor([[ 73.,  80.,  75.],\n",
            "        [ 96.,  98., 100.]]), tensor([[152.],\n",
            "        [196.]])] ---\n",
            "Epoch    8/20 Batch 1/3 Cost: 1.920283\n",
            "--- 1 + [tensor([[73., 66., 70.],\n",
            "        [93., 88., 93.]]), tensor([[142.],\n",
            "        [185.]])] ---\n",
            "Epoch    8/20 Batch 2/3 Cost: 10.358597\n",
            "--- 2 + [tensor([[89., 91., 90.]]), tensor([[180.]])] ---\n",
            "Epoch    8/20 Batch 3/3 Cost: 3.988107\n",
            "--- 0 + [tensor([[ 96.,  98., 100.],\n",
            "        [ 89.,  91.,  90.]]), tensor([[196.],\n",
            "        [180.]])] ---\n",
            "Epoch    9/20 Batch 1/3 Cost: 0.568480\n",
            "--- 1 + [tensor([[73., 80., 75.],\n",
            "        [73., 66., 70.]]), tensor([[152.],\n",
            "        [142.]])] ---\n",
            "Epoch    9/20 Batch 2/3 Cost: 6.341614\n",
            "--- 2 + [tensor([[93., 88., 93.]]), tensor([[185.]])] ---\n",
            "Epoch    9/20 Batch 3/3 Cost: 7.800930\n",
            "--- 0 + [tensor([[ 73.,  80.,  75.],\n",
            "        [ 96.,  98., 100.]]), tensor([[152.],\n",
            "        [196.]])] ---\n",
            "Epoch   10/20 Batch 1/3 Cost: 5.950714\n",
            "--- 1 + [tensor([[73., 66., 70.],\n",
            "        [89., 91., 90.]]), tensor([[142.],\n",
            "        [180.]])] ---\n",
            "Epoch   10/20 Batch 2/3 Cost: 4.552931\n",
            "--- 2 + [tensor([[93., 88., 93.]]), tensor([[185.]])] ---\n",
            "Epoch   10/20 Batch 3/3 Cost: 5.165050\n",
            "--- 0 + [tensor([[ 96.,  98., 100.],\n",
            "        [ 93.,  88.,  93.]]), tensor([[196.],\n",
            "        [185.]])] ---\n",
            "Epoch   11/20 Batch 1/3 Cost: 2.655915\n",
            "--- 1 + [tensor([[89., 91., 90.],\n",
            "        [73., 66., 70.]]), tensor([[180.],\n",
            "        [142.]])] ---\n",
            "Epoch   11/20 Batch 2/3 Cost: 4.570726\n",
            "--- 2 + [tensor([[73., 80., 75.]]), tensor([[152.]])] ---\n",
            "Epoch   11/20 Batch 3/3 Cost: 7.856945\n",
            "--- 0 + [tensor([[93., 88., 93.],\n",
            "        [73., 80., 75.]]), tensor([[185.],\n",
            "        [152.]])] ---\n",
            "Epoch   12/20 Batch 1/3 Cost: 5.516622\n",
            "--- 1 + [tensor([[73., 66., 70.],\n",
            "        [89., 91., 90.]]), tensor([[142.],\n",
            "        [180.]])] ---\n",
            "Epoch   12/20 Batch 2/3 Cost: 4.523823\n",
            "--- 2 + [tensor([[ 96.,  98., 100.]]), tensor([[196.]])] ---\n",
            "Epoch   12/20 Batch 3/3 Cost: 0.632823\n",
            "--- 0 + [tensor([[73., 66., 70.],\n",
            "        [73., 80., 75.]]), tensor([[142.],\n",
            "        [152.]])] ---\n",
            "Epoch   13/20 Batch 1/3 Cost: 5.973551\n",
            "--- 1 + [tensor([[ 96.,  98., 100.],\n",
            "        [ 93.,  88.,  93.]]), tensor([[196.],\n",
            "        [185.]])] ---\n",
            "Epoch   13/20 Batch 2/3 Cost: 3.325423\n",
            "--- 2 + [tensor([[89., 91., 90.]]), tensor([[180.]])] ---\n",
            "Epoch   13/20 Batch 3/3 Cost: 2.933994\n",
            "--- 0 + [tensor([[ 96.,  98., 100.],\n",
            "        [ 73.,  66.,  70.]]), tensor([[196.],\n",
            "        [142.]])] ---\n",
            "Epoch   14/20 Batch 1/3 Cost: 4.606066\n",
            "--- 1 + [tensor([[93., 88., 93.],\n",
            "        [73., 80., 75.]]), tensor([[185.],\n",
            "        [152.]])] ---\n",
            "Epoch   14/20 Batch 2/3 Cost: 5.114324\n",
            "--- 2 + [tensor([[89., 91., 90.]]), tensor([[180.]])] ---\n",
            "Epoch   14/20 Batch 3/3 Cost: 2.375529\n",
            "--- 0 + [tensor([[93., 88., 93.],\n",
            "        [73., 66., 70.]]), tensor([[185.],\n",
            "        [142.]])] ---\n",
            "Epoch   15/20 Batch 1/3 Cost: 9.189795\n",
            "--- 1 + [tensor([[ 96.,  98., 100.],\n",
            "        [ 89.,  91.,  90.]]), tensor([[196.],\n",
            "        [180.]])] ---\n",
            "Epoch   15/20 Batch 2/3 Cost: 3.290468\n",
            "--- 2 + [tensor([[73., 80., 75.]]), tensor([[152.]])] ---\n",
            "Epoch   15/20 Batch 3/3 Cost: 4.038238\n",
            "--- 0 + [tensor([[ 96.,  98., 100.],\n",
            "        [ 73.,  66.,  70.]]), tensor([[196.],\n",
            "        [142.]])] ---\n",
            "Epoch   16/20 Batch 1/3 Cost: 5.911026\n",
            "--- 1 + [tensor([[89., 91., 90.],\n",
            "        [93., 88., 93.]]), tensor([[180.],\n",
            "        [185.]])] ---\n",
            "Epoch   16/20 Batch 2/3 Cost: 4.059720\n",
            "--- 2 + [tensor([[73., 80., 75.]]), tensor([[152.]])] ---\n",
            "Epoch   16/20 Batch 3/3 Cost: 5.095168\n",
            "--- 0 + [tensor([[ 96.,  98., 100.],\n",
            "        [ 73.,  80.,  75.]]), tensor([[196.],\n",
            "        [152.]])] ---\n",
            "Epoch   17/20 Batch 1/3 Cost: 1.106071\n",
            "--- 1 + [tensor([[93., 88., 93.],\n",
            "        [89., 91., 90.]]), tensor([[185.],\n",
            "        [180.]])] ---\n",
            "Epoch   17/20 Batch 2/3 Cost: 5.939598\n",
            "--- 2 + [tensor([[73., 66., 70.]]), tensor([[142.]])] ---\n",
            "Epoch   17/20 Batch 3/3 Cost: 8.171489\n",
            "--- 0 + [tensor([[ 73.,  80.,  75.],\n",
            "        [ 96.,  98., 100.]]), tensor([[152.],\n",
            "        [196.]])] ---\n",
            "Epoch   18/20 Batch 1/3 Cost: 5.143266\n",
            "--- 1 + [tensor([[93., 88., 93.],\n",
            "        [89., 91., 90.]]), tensor([[185.],\n",
            "        [180.]])] ---\n",
            "Epoch   18/20 Batch 2/3 Cost: 3.970593\n",
            "--- 2 + [tensor([[73., 66., 70.]]), tensor([[142.]])] ---\n",
            "Epoch   18/20 Batch 3/3 Cost: 6.346577\n",
            "--- 0 + [tensor([[73., 66., 70.],\n",
            "        [89., 91., 90.]]), tensor([[142.],\n",
            "        [180.]])] ---\n",
            "Epoch   19/20 Batch 1/3 Cost: 4.651275\n",
            "--- 1 + [tensor([[ 96.,  98., 100.],\n",
            "        [ 73.,  80.,  75.]]), tensor([[196.],\n",
            "        [152.]])] ---\n",
            "Epoch   19/20 Batch 2/3 Cost: 5.303147\n",
            "--- 2 + [tensor([[93., 88., 93.]]), tensor([[185.]])] ---\n",
            "Epoch   19/20 Batch 3/3 Cost: 6.408849\n",
            "--- 0 + [tensor([[ 96.,  98., 100.],\n",
            "        [ 93.,  88.,  93.]]), tensor([[196.],\n",
            "        [185.]])] ---\n",
            "Epoch   20/20 Batch 1/3 Cost: 2.503319\n",
            "--- 1 + [tensor([[89., 91., 90.],\n",
            "        [73., 66., 70.]]), tensor([[180.],\n",
            "        [142.]])] ---\n",
            "Epoch   20/20 Batch 2/3 Cost: 4.460885\n",
            "--- 2 + [tensor([[73., 80., 75.]]), tensor([[152.]])] ---\n",
            "Epoch   20/20 Batch 3/3 Cost: 7.530978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha0TnEPWVb31"
      },
      "source": [
        "Cost의 값이 점차 작아집니다. (사실 아직 에포크를 더 늘려서 훈련하면 Cost의 값이 더 작아질 여지가 있습니다. 에포크를 늘려서도 훈련해보세요.) 이제 모델의 입력으로 임의의 값을 넣어 예측값을 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwHypoX6VeBI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06807ac3-f3c7-447c-9b51-f8f071b1ff61"
      },
      "source": [
        "# 임의의 입력 [70, 85, 75]를 선언\n",
        "new_var =  torch.FloatTensor([[70, 85, 75]]) \n",
        "# 입력한 값 [70, 85, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
        "pred_y = model(new_var) \n",
        "print(\"훈련 후 입력이 70, 85, 75일 때의 예측값 :\", pred_y) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 후 입력이 70, 85, 75일 때의 예측값 : tensor([[-25.6291]], grad_fn=<AddmmBackward>)\n"
          ]
        }
      ]
    }
  ]
}