{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_PyTorch(nn.Module로 구현 선형회귀).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPA0lF1oGhY0WhdfX7289BI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmongsil1105/colab_ipynb/blob/main/AI_PyTorch(nn_Module%EB%A1%9C_%EA%B5%AC%ED%98%84_%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-NNZRBxKiKJ"
      },
      "source": [
        "# nn.Module로 구현하는 선형 회귀"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DUf44ONK76V"
      },
      "source": [
        " 파이토치에서는 선형 회귀 모델이 nn.Linear()라는 함수로, \n",
        " \n",
        " 또 평균 제곱오차가 nn.functional.mse_loss()라는 함수로 구현되어 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D2Zg5L-LGSc"
      },
      "source": [
        "1. 단순 선형 회귀 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqX75vNdEMgk"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYZCahzOKkWn",
        "outputId": "1161b428-b72b-4954-b129-161150aaf892"
      },
      "source": [
        "torch.manual_seed(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f3e78b4bb50>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzDfZ8--LTA8"
      },
      "source": [
        "   데이터 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xixs3eFLTpu"
      },
      "source": [
        "# 데이터\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivZxNVGrLbrM"
      },
      "source": [
        "선형 회귀 모델을 구현 ==> nn.Linear()는 입력의 차원, 출력의 차원을 인수로 받습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo4TO_f5LcsU"
      },
      "source": [
        "# 모델을 선언 및 초기화. 단순 선형 회귀이므로 input_dim=1, output_dim=1.\n",
        "model = nn.Linear(1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hMOExj9LrKE"
      },
      "source": [
        "하나의 입력 에 대해서 하나의 출력 을 가지므로, \n",
        "\n",
        "입력 차원과 출력 차원 모두 1을 인수로 사용하였습니다. \n",
        "\n",
        "model에는 가중치 W와 편향 b가 저장되어져 있습니다. \n",
        "\n",
        "이 값은 model.parameters()라는 함수를 사용하여 불러올 수 있는데, 한 번 출력해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa_p_kapLv1s",
        "outputId": "bd55c3f3-2aca-4762-dff0-64e11149c06d"
      },
      "source": [
        "print(list(model.parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[-0.2816]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.1690], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypB5q_uhL27E"
      },
      "source": [
        "2개의 값이 출력되는데 \"첫번째 값이 W\"고, \"두번째 값이 b\"에 해당됩니다. \n",
        "\n",
        "두 값 모두 현재는 랜덤 초기화가 되어져 있습니다. \n",
        "\n",
        "그리고 두 값 모두 학습의 대상이므로 requires_grad=True가 되어져 있는 것을 볼 수 있습니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2Leb_pKMJmy"
      },
      "source": [
        "-------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScH2dinlML1b"
      },
      "source": [
        "이제 옵티마이저를 정의합니다. model.parameters()를 사용하여 W와 b를 전달합니다.\n",
        "\n",
        "\n",
        "학습률(learning rate)은 0.01로 정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D6HJg-wMRP3"
      },
      "source": [
        "# optimizer 설정. 경사 하강법 SGD를 사용하고 learning rate를 의미하는 lr은 0.01\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-YdWzXFMXgT",
        "outputId": "644c3fab-dc27-4e21-b963-b5d4bb6677b9"
      },
      "source": [
        "# 전체 훈련 데이터에 대해 경사 하강법을 2,000회 반복\n",
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
        "\n",
        "    # cost로 H(x) 개선하는 부분\n",
        "    # gradient를 0으로 초기화\n",
        "    optimizer.zero_grad()\n",
        "    # 비용 함수를 미분하여 gradient 계산\n",
        "    cost.backward() # backward 연산\n",
        "    # W와 b를 업데이트\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "    # 100번마다 로그 출력\n",
        "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "          epoch, nb_epochs, cost.item()\n",
        "      ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 25.865189\n",
            "Epoch  100/2000 Cost: 0.043357\n",
            "Epoch  200/2000 Cost: 0.026792\n",
            "Epoch  300/2000 Cost: 0.016556\n",
            "Epoch  400/2000 Cost: 0.010231\n",
            "Epoch  500/2000 Cost: 0.006322\n",
            "Epoch  600/2000 Cost: 0.003907\n",
            "Epoch  700/2000 Cost: 0.002414\n",
            "Epoch  800/2000 Cost: 0.001492\n",
            "Epoch  900/2000 Cost: 0.000922\n",
            "Epoch 1000/2000 Cost: 0.000570\n",
            "Epoch 1100/2000 Cost: 0.000352\n",
            "Epoch 1200/2000 Cost: 0.000217\n",
            "Epoch 1300/2000 Cost: 0.000134\n",
            "Epoch 1400/2000 Cost: 0.000083\n",
            "Epoch 1500/2000 Cost: 0.000051\n",
            "Epoch 1600/2000 Cost: 0.000032\n",
            "Epoch 1700/2000 Cost: 0.000020\n",
            "Epoch 1800/2000 Cost: 0.000012\n",
            "Epoch 1900/2000 Cost: 0.000007\n",
            "Epoch 2000/2000 Cost: 0.000005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdM1pACTKgo5"
      },
      "source": [
        " * 학습이 완료되었습니다. \n",
        " \n",
        "  Cost의 값이 매우 작습니다. \n",
        "  \n",
        "  W와 b의 값도 최적화가 되었는지 확인해봅시다.\n",
        "\n",
        "  x에 임의의 값 4를 넣어 모델이 예측하는 y의 값을 확인해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WN0liqBpKhTs",
        "outputId": "6eee3482-ffa3-4495-a838-fe29ebcf89ca"
      },
      "source": [
        "# 임의의 입력 4를 선언\n",
        "new_var =  torch.FloatTensor([[4.0]]) \n",
        "# 입력한 값 4에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
        "pred_y = model(new_var) # forward 연산\n",
        "# y = 2x 이므로 입력이 4라면 y가 8에 가까운 값이 나와야 제대로 학습이 된 것\n",
        "print(\"훈련 후 입력이 4일 때의 예측값 :\", pred_y) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 후 입력이 4일 때의 예측값 : tensor([[7.9957]], grad_fn=<AddmmBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKtYDcLXLTEJ"
      },
      "source": [
        " * 사실 이 문제의 정답은 y = 2x가 정답이므로 \n",
        " \n",
        "   y값이 8에 가까우면 W와 b의 값이 어느정도 최적화가 된 것으로 볼 수 있습니다. \n",
        "   \n",
        "   실제로 예측된 y값은 8에 매우 가깝습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3rWMNy9LioF"
      },
      "source": [
        " * 이제 학습 후의 W와 b의 값을 출력해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYwypy-4Kw5k",
        "outputId": "4681a679-07f5-4ae8-e3df-4c3d1e80f3a5"
      },
      "source": [
        "print(list(model.parameters()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[1.9975]], requires_grad=True), Parameter containing:\n",
            "tensor([0.0057], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN2R4_qMLm8J"
      },
      "source": [
        " * W의 값이 2에 가깝고, b의 값이 0에 가까운 것을 볼 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwaS4TVbLq0y"
      },
      "source": [
        " ---------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjskO-T_Ls3h"
      },
      "source": [
        " * H(x)식에 입력 x로부터 예측된 y를 얻는 것을 forward 연산이라고 합니다.\n",
        "\n",
        " *학습 전, prediction = model(x_train)은 x_train으로부터 \"예측값을 리턴\"하므로 \"forward 연산\"입니다.\n",
        "\n",
        " *학습 후, pred_y = model(new_var)는 임의의 값 new_var로부터 \"예측값을 리턴\"하므로 \"forward 연산\"입니다.\n",
        "\n",
        " *학습 과정에서 \"비용 함수를 미분하여 기울기를 구하는 것\"을 \"backward 연산\"이라고 합니다.\n",
        "\n",
        " *cost.backward()는 비용 함수로부터 기울기를 구하라는 의미이며  \"backward 연산\"입니다."
      ]
    }
  ]
}