{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_PyTorch(선형회귀 모델만들기).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMgPI/hFWIYFnglDgRGQUZ5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmongsil1105/colab_ipynb/blob/main/AI_PyTorch(%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80_%EB%AA%A8%EB%8D%B8%EB%A7%8C%EB%93%A4%EA%B8%B0).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE_XXvwWovFv"
      },
      "source": [
        " * 기본 셋팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhypyEZonaqw"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5jgKXbVncwM",
        "outputId": "baa33652-376f-4ada-ad71-2201843b0db2"
      },
      "source": [
        "# 현재 실습하고 있는 파이썬 코드를 재실행해도 다음에도 같은 결과가 나오도록 랜덤 시드(random seed)를 줍니다.\n",
        "torch.manual_seed(1)    # seed값을 지정하면 random값은 일정하다!!\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7faa7ecd3b30>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzTv5AkmoztD"
      },
      "source": [
        " * 변수 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E41Zv--tob_V",
        "outputId": "d42cc6ae-2183-4825-e045-0a0e086bddad"
      },
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])\n",
        "print(x_train)\n",
        "print(x_train.shape)\n",
        "print(y_train)\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]])\n",
            "torch.Size([3, 1])\n",
            "tensor([[2.],\n",
            "        [4.],\n",
            "        [6.]])\n",
            "torch.Size([3, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLtsNaMMo2H2"
      },
      "source": [
        " * 가중치와 편향의 초기화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2Cf1OSvo-xL"
      },
      "source": [
        " * 선형 회귀란 학습 데이터와 가장 잘 맞는 하나의 직선을 찾는 일입니다.\n",
        "\n",
        " 그리고 가장 잘 맞는 직선을 정의하는 것은 바로 와 입니다.\n",
        "\n",
        " 선형 회귀의 목표는 가장 잘 맞는 직선을 정의하는 와 의 값을 찾는 것입니다.\n",
        "\n",
        " 우선 가중치 W를 0으로 초기화하고, 이 값을 출력해보겠습니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0r3flWUo6DG",
        "outputId": "59bf3f3a-61de-4082-f083-70a3e2349ca9"
      },
      "source": [
        " # 가중치 W를 0으로 초기화하고 학습을 통해 값이 변경되는 변수임을 명시함.\n",
        "W = torch.zeros(1, requires_grad=True) \n",
        "# 가중치 W를 출력\n",
        "print(W) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL76XFhZpRla"
      },
      "source": [
        " * 마찬가지로 편향(Bias) 도 0으로 초기화하고, 학습을 통해 값이 변경되는 변수임을 명시합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKIOOIZfpTdl",
        "outputId": "cb95ca0d-45bd-4f06-c1bb-f034faa37a8f"
      },
      "source": [
        "b = torch.zeros(1, requires_grad=True)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2HDtbmqpfj2"
      },
      "source": [
        " * 현재 가중치 W와  b 둘 다 0이므로 현 직선의 방정식은 다음과 같습니다.  \n",
        "   y = 0 * x + 0\n",
        "\n",
        "  지금 상태에선 에 어떤 값이 들어가도 가설은 0을 예측하게 됩니다. \n",
        "  \n",
        "  즉, 아직 적절한 와 의 값이 아닙니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW1dyiGop0WE"
      },
      "source": [
        "# * **가설** 세우기\n",
        "\n",
        "   파이토치 코드 상으로 직선의 방정식에 해당되는 가설을 선언합니다\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beJkJvh2qA-f",
        "outputId": "7edece2f-6b12-4862-ed72-1e76fd0129b2"
      },
      "source": [
        "hypothesis = x_train * W + b\n",
        "print(hypothesis)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tj7jfnlCqHjd"
      },
      "source": [
        "# * 비용 함수 선언하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJslwG-OqJQh"
      },
      "source": [
        " * 파이토치 코드 상으로 선형 회귀의 비용 함수에 해당되는 평균 제곱 오차를 선언합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWNabnX5qRFp",
        "outputId": "6551c5bc-e51c-4560-d252-f35a18f09d8c"
      },
      "source": [
        "# 앞서 배운 torch.mean으로 평균을 구한다.\n",
        "cost = torch.mean((hypothesis - y_train) ** 2) \n",
        "print(cost)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(18.6667, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOpZiizAqYie"
      },
      "source": [
        "# * 경사 하강법 구현하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JruAtpzKqcEC"
      },
      "source": [
        " * 이제 경사 하강법을 구현합니다. \n",
        " \n",
        "   아래의 'SGD'는 \"확률적 경사 하강법\"의 일종입니다. \n",
        "   \n",
        "   lr은 학습률(learning rate)를 의미합니다.\n",
        "\n",
        "   ==> 학습 대상인 W와 b가 SGD의 입력이 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAU7zGELqn7U"
      },
      "source": [
        "optimizer = optim.SGD([W, b], lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9FyvhVdq6tV"
      },
      "source": [
        "# gradient를 0으로 초기화\n",
        "optimizer.zero_grad()  # 기울기를 초기화해야만 새로운 가중치 편향에 대해서 새로운 기울기를 구할 수 있다.\n",
        "# 비용 함수를 미분하여 gradient 계산(cost.backward() 함수를 호출하면 가중치 W와 편향 b에 대한 기울기가 계산)\n",
        "cost.backward() \n",
        "# W와 b를 업데이트\n",
        "# 경사 하강법 최적화 함수 opimizer의 .step() 함수를 호출하여 \n",
        "# 인수로 들어갔던 W와 b에서 리턴되는 변수들의 기울기에 학습률(learining rate) 0.01을 곱하여 빼줌으로서 업데이트합니다.\n",
        "optimizer.step() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7Fw58EardbA"
      },
      "source": [
        "# * 전체 코드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpQeq8iqrc_5",
        "outputId": "6a2225a2-396d-4645-a4b0-f7e4656986de"
      },
      "source": [
        "# 데이터\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])\n",
        "# 모델 초기화\n",
        "W = torch.zeros(1, requires_grad=True)  # 가중치(W) 초기화\n",
        "b = torch.zeros(1, requires_grad=True)  # 바이어스(b) 초기화\n",
        "# optimizer 설정 ==> 여기서는 확률적 경사하강법(매번 변경하지 않고 초반 몇번만 수정하고...나머지는 계속 가던 값으로 계산.)\n",
        "optimizer = optim.SGD([W, b], lr=0.01)  # 경사하강법(lr(learning rate)는 경사를 따라서 값이 변경될 때 얼마나 큰 폭으로 값을 이동할 것이냐?)\n",
        "\n",
        "nb_epochs = 1999 # 원하는만큼 경사 하강법을 반복\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = x_train * W + b\n",
        "    #print(hypothesis)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()  # 기울기를 0으로 세팅!!!\n",
        "    cost.backward()        # 전파/역전파를 반복해서 cost값을 최소화시키도록 하다\n",
        "    optimizer.step()       # 인수로 들어갔던 W와 b에서 리턴되는 변수들의 기울기에 학습률(learining rate) 0.01을 곱하여 빼줌으로서 업데이트\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:           \n",
        "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, W.item(), b.item(), cost.item()\n",
        "        ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/1999 W: 0.187, b: 0.080 Cost: 18.666666\n",
            "Epoch  100/1999 W: 1.746, b: 0.578 Cost: 0.048171\n",
            "Epoch  200/1999 W: 1.800, b: 0.454 Cost: 0.029767\n",
            "Epoch  300/1999 W: 1.843, b: 0.357 Cost: 0.018394\n",
            "Epoch  400/1999 W: 1.876, b: 0.281 Cost: 0.011366\n",
            "Epoch  500/1999 W: 1.903, b: 0.221 Cost: 0.007024\n",
            "Epoch  600/1999 W: 1.924, b: 0.174 Cost: 0.004340\n",
            "Epoch  700/1999 W: 1.940, b: 0.136 Cost: 0.002682\n",
            "Epoch  800/1999 W: 1.953, b: 0.107 Cost: 0.001657\n",
            "Epoch  900/1999 W: 1.963, b: 0.084 Cost: 0.001024\n",
            "Epoch 1000/1999 W: 1.971, b: 0.066 Cost: 0.000633\n",
            "Epoch 1100/1999 W: 1.977, b: 0.052 Cost: 0.000391\n",
            "Epoch 1200/1999 W: 1.982, b: 0.041 Cost: 0.000242\n",
            "Epoch 1300/1999 W: 1.986, b: 0.032 Cost: 0.000149\n",
            "Epoch 1400/1999 W: 1.989, b: 0.025 Cost: 0.000092\n",
            "Epoch 1500/1999 W: 1.991, b: 0.020 Cost: 0.000057\n",
            "Epoch 1600/1999 W: 1.993, b: 0.016 Cost: 0.000035\n",
            "Epoch 1700/1999 W: 1.995, b: 0.012 Cost: 0.000022\n",
            "Epoch 1800/1999 W: 1.996, b: 0.010 Cost: 0.000013\n",
            "Epoch 1900/1999 W: 1.997, b: 0.008 Cost: 0.000008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWro1xxv2swB"
      },
      "source": [
        " * 2000번 반복후 가중치(W)는 2,000에 가깝게 나오고\n",
        "\n",
        "   Cost(오차값)는 거의 0에 가깝게 나왔다.\n",
        "\n",
        "   기울기는 y = 2x 에 가깝게 예측이 된 것을 확인 할 수 있다."
      ]
    }
  ]
}